---
title: P5 - Embeddings on-prem con Ollama (nomic-embed-text)
labels: P5, ai, inference, ollama
milestone: P5
---

## Contexto
Evitar dependencia externa para embeddings.

## Alcance
- Desplegar Ollama en host (CPU/GPU opcional).
- Endpoint interno para generar embeddings.
- Rotación/actualización de modelos.

## Tareas
- [ ] Instalar y probar modelo `nomic-embed-text`.
- [ ] Integración con pipeline de ingestión.
- [ ] Métricas de latencia y throughput.

## Criterios de aceptación
- [ ] Embeddings se generan localmente de forma estable.
